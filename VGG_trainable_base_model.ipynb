{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9f4764-dd71-4dea-863f-c51c0809859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3c4463-0a3e-4896-923a-6b9e293cb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attemtion to the path \n",
    "base_dir = '../real_vs_fake/real-vs-fake'\n",
    "#|--project\n",
    "#|-----TechLabs-DL-2024\n",
    "#|----------model.ipynb\n",
    "#|----------README.md\n",
    "#|-----real-vs-fake\n",
    "#|----------test\n",
    "#|----------train\n",
    "#|----------valid\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20489172-5bd3-4a0b-addd-3e574891d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102041 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 250\n",
    "img_size = (150,150)\n",
    "# sample_count = 102041 not needed anymore\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# train_generator.samples = 2 * sample_count  # causing errors in training\n",
    "#train_generator.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec11eb11-5f4a-4034-bc7f-d8afb889cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load VGG16\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False,  # Exclude the fully connected layer\n",
    "    input_shape=(150, 150, 3)  # Specify the input shape\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2696ebea-cae3-471a-822f-0c14e200f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Freeze the first 10 layers of the base model\n",
    "for layer in base_model.layers[:8]:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Leave the remaining layers trainable\n",
    "for layer in base_model.layers[8:]:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761e073c-7955-4d1a-80cd-760e27fb16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,  # Add the base model as the first layer\n",
    "    layers.GlobalAveragePooling2D(),  # Reduces dimensions without further convolutions\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373139bf-f46d-4985-984a-7e5de7c4daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding early stopping to not miss best model\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Continiously validation loss\n",
    "    mode='min',             # Stops when val_loss is minimized\n",
    "    patience=3,             # Waits 3 epochs id no improvement\n",
    "    restore_best_weights=True  # Restores best model weights when training stops\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1d2c3-528e-4594-8950-ed8a0a3d68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 21:39:40.164494: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/408 [==============================] - ETA: 0s - loss: 0.7335 - accuracy: 0.5044 "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-12 00:23:06.991485: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "408/408 [==============================] - 10702s 26s/step - loss: 0.7335 - accuracy: 0.5044 - val_loss: 0.6931 - val_accuracy: 0.5002\n",
      "Epoch 2/100\n",
      "408/408 [==============================] - 10768s 26s/step - loss: 0.6932 - accuracy: 0.5021 - val_loss: 0.6932 - val_accuracy: 0.5000\n",
      "Epoch 3/100\n",
      "408/408 [==============================] - ETA: 0s - loss: 0.6932 - accuracy: 0.5010 "
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # number of batches per epoch\n",
    "    epochs=100,  # high number of epochs is ok due to early stopping\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping]   # EarlyStopping callback \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924657b-3de0-499a-9f57-1d91423542e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the Test Set\n",
    "print(\"Evaluating on Test Set:\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "Y_pred_test = model.predict(test_generator)\n",
    "y_pred_test = np.round(Y_pred_test).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(test_generator.classes, y_pred_test))\n",
    "\n",
    "print('Classification Report - Test Set')\n",
    "print(classification_report(test_generator.classes, y_pred_test, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // valid_generator.batch_size)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "Y_pred_val = model.predict(valid_generator)\n",
    "y_pred_val = np.round(Y_pred_val).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Validation Set')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred_val))\n",
    "\n",
    "print('Classification Report - Validation Set')\n",
    "print(classification_report(valid_generator.classes, y_pred_val, target_names=['Real', 'Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeb84a-1a50-44fb-8791-8601c86c6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_trainable_VGG16.h5')  # HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f64a8-4a1b-4193-a642-9ce099ca5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(7)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb7624-c679-4861-b13c-581b23e9bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef61bac-7d84-462e-924c-c2c6f10663f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e75a5-31de-4259-8b0d-bda5e2b812ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add model history to CSV so that we can make a cool graph out of it later\n",
    "# Pls change layer name :)\n",
    "history_df.to_csv(\"trainable_VGG16_model_history.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdcb3d-d321-4a6a-bc7c-d06435d87846",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbab2c-98a7-4fa8-9e1f-88c871d03612",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
