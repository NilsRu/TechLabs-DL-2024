{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9f4764-dd71-4dea-863f-c51c0809859c",
   "metadata": {
    "id": "6c9f4764-dd71-4dea-863f-c51c0809859c"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd\n",
    "from keras.applications.vgg16 import VGG16\n",
    "import numpy as np\n",
    "import random\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3c4463-0a3e-4896-923a-6b9e293cb164",
   "metadata": {
    "id": "9b3c4463-0a3e-4896-923a-6b9e293cb164"
   },
   "outputs": [],
   "source": [
    "# Pay attemtion to the path\n",
    "base_dir = '../real_vs_fake/real-vs-fake'\n",
    "#|--project\n",
    "#|-----TechLabs-DL-2024\n",
    "#|----------model.ipynb\n",
    "#|----------README.md\n",
    "#|-----real-vs-fake\n",
    "#|----------test\n",
    "#|----------train\n",
    "#|----------valid\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20489172-5bd3-4a0b-addd-3e574891d992",
   "metadata": {
    "id": "20489172-5bd3-4a0b-addd-3e574891d992",
    "outputId": "45cadfc9-6139-4d32-839a-d87905a45f5a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 30613 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "img_size = (150,150)\n",
    "# sample_count = 102041 not needed anymore\n",
    "\n",
    "# Use ImageDataGenerator with validation_split for sampling\n",
    "train_datagen = ImageDataGenerator(rescale=1./255, validation_split=0.7)  # 50% of images\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=\"training\", # this will train the model on only half of the images\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# train_generator.samples = 2 * sample_count  # causing errors in training\n",
    "#train_generator.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec11eb11-5f4a-4034-bc7f-d8afb889cb50",
   "metadata": {
    "id": "ec11eb11-5f4a-4034-bc7f-d8afb889cb50"
   },
   "outputs": [],
   "source": [
    "# Load VG\n",
    "base_model = VGG16(weights='imagenet', include_top=False, input_shape=(img_size[0], img_size[1], 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2696ebea-cae3-471a-822f-0c14e200f2bc",
   "metadata": {
    "id": "2696ebea-cae3-471a-822f-0c14e200f2bc"
   },
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "761e073c-7955-4d1a-80cd-760e27fb16db",
   "metadata": {
    "id": "761e073c-7955-4d1a-80cd-760e27fb16db",
    "outputId": "beea6487-3928-40c4-daac-362143858ea8"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,  # Add the base model as the first layer\n",
    "    layers.GlobalAveragePooling2D(),  # Reduces dimensions without further convolutions\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "373139bf-f46d-4985-984a-7e5de7c4daa6",
   "metadata": {
    "id": "373139bf-f46d-4985-984a-7e5de7c4daa6"
   },
   "outputs": [],
   "source": [
    "# adding early stopping to not miss best model\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Continiously validation loss\n",
    "    mode='min',             # Stops when val_loss is minimized\n",
    "    patience=3,             # Waits 3 epochs id no improvement\n",
    "    restore_best_weights=True  # Restores best model weights when training stops\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1d2c3-528e-4594-8950-ed8a0a3d68cb",
   "metadata": {
    "id": "e5e1d2c3-528e-4594-8950-ed8a0a3d68cb",
    "outputId": "fd0d0ce7-8fa3-4a2f-a6b6-9965c3f2723e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 20:54:29.898502: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  10/1530 [..............................] - ETA: 1:07:47 - loss: 3.6616 - accuracy: 0.5000"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # number of batches per epoch\n",
    "    epochs=100,  # high number of epochs is ok due to early stopping\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping]   # EarlyStopping callback\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924657b-3de0-499a-9f57-1d91423542e2",
   "metadata": {
    "id": "8924657b-3de0-499a-9f57-1d91423542e2",
    "outputId": "e6f7a238-1273-415f-e061-b5d65712ef6a"
   },
   "outputs": [],
   "source": [
    "# Evaluate on the Test Set\n",
    "print(\"Evaluating on Test Set:\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "Y_pred_test = model.predict(test_generator)\n",
    "y_pred_test = np.round(Y_pred_test).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(test_generator.classes, y_pred_test))\n",
    "\n",
    "print('Classification Report - Test Set')\n",
    "print(classification_report(test_generator.classes, y_pred_test, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // valid_generator.batch_size)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "Y_pred_val = model.predict(valid_generator)\n",
    "y_pred_val = np.round(Y_pred_val).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Validation Set')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred_val))\n",
    "\n",
    "print('Classification Report - Validation Set')\n",
    "print(classification_report(valid_generator.classes, y_pred_val, target_names=['Real', 'Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bebeb84a-1a50-44fb-8791-8601c86c6439",
   "metadata": {
    "id": "bebeb84a-1a50-44fb-8791-8601c86c6439"
   },
   "outputs": [],
   "source": [
    "model.save('pretrained_trainable_VGG16.h5')  # HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f64a8-4a1b-4193-a642-9ce099ca5913",
   "metadata": {
    "id": "699f64a8-4a1b-4193-a642-9ce099ca5913",
    "outputId": "d420f9e8-3cb7-49ba-cda9-c6820a4353dc"
   },
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(7)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47cb7624-c679-4861-b13c-581b23e9bfcc",
   "metadata": {
    "id": "47cb7624-c679-4861-b13c-581b23e9bfcc"
   },
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ef61bac-7d84-462e-924c-c2c6f10663f8",
   "metadata": {
    "id": "7ef61bac-7d84-462e-924c-c2c6f10663f8",
    "outputId": "71aaa4d1-4e91-403b-bd11-ab5beef65073"
   },
   "outputs": [],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69e75a5-31de-4259-8b0d-bda5e2b812ba",
   "metadata": {
    "id": "c69e75a5-31de-4259-8b0d-bda5e2b812ba"
   },
   "outputs": [],
   "source": [
    "# lets add model history to CSV so that we can make a cool graph out of it later\n",
    "# Pls change layer name :)\n",
    "history_df.to_csv(\"trainable_VGG16_layer_model_history.csv\", index = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96bdcb3d-d321-4a6a-bc7c-d06435d87846",
   "metadata": {
    "id": "96bdcb3d-d321-4a6a-bc7c-d06435d87846"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4bbab2c-98a7-4fa8-9e1f-88c871d03612",
   "metadata": {
    "id": "b4bbab2c-98a7-4fa8-9e1f-88c871d03612"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
