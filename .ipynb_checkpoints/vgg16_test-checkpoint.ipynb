{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bed05b90-ea80-4380-8029-d8056740dc7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Mixed precision compatibility check (mixed_float16): WARNING\n",
      "The dtype policy mixed_float16 may run slowly because this machine does not have a GPU. Only Nvidia GPUs with compute capability of at least 7.0 run quickly with mixed_float16.\n",
      "If you will use compatible GPU(s) not attached to this host, e.g. by running a multi-worker model, you can ignore this warning. This message will only be logged once\n",
      "Found 102041 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n",
      "Found 20000 files belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 21:34:11.546046: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype string and shape [102041]\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-09-10 21:34:11.546296: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_4' with dtype int32 and shape [102041]\n",
      "\t [[{{node Placeholder/_4}}]]\n",
      "2024-09-10 21:34:12.582389: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n",
      "2024-09-10 21:34:22.966313: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 12 of 1000\n",
      "2024-09-10 21:34:32.900749: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 49 of 1000\n",
      "2024-09-10 21:34:42.891065: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 86 of 1000\n",
      "2024-09-10 21:34:53.234030: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 124 of 1000\n",
      "2024-09-10 21:35:02.946401: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 153 of 1000\n",
      "2024-09-10 21:35:13.431376: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 172 of 1000\n",
      "2024-09-10 21:35:23.240235: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 199 of 1000\n",
      "2024-09-10 21:35:33.012055: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 227 of 1000\n",
      "2024-09-10 21:35:43.695753: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 258 of 1000\n",
      "2024-09-10 21:35:53.685629: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 296 of 1000\n",
      "2024-09-10 21:36:03.365703: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 324 of 1000\n",
      "2024-09-10 21:36:14.290742: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 346 of 1000\n",
      "2024-09-10 21:36:22.888214: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 372 of 1000\n",
      "2024-09-10 21:36:33.001171: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 390 of 1000\n",
      "2024-09-10 21:36:42.904972: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 441 of 1000\n",
      "2024-09-10 21:36:53.318045: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 480 of 1000\n",
      "2024-09-10 21:37:03.113012: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 525 of 1000\n",
      "2024-09-10 21:37:13.182612: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 575 of 1000\n",
      "2024-09-10 21:37:22.989240: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 622 of 1000\n",
      "2024-09-10 21:37:33.419034: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 664 of 1000\n",
      "2024-09-10 21:37:43.012954: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 707 of 1000\n",
      "2024-09-10 21:37:53.023372: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 755 of 1000\n",
      "2024-09-10 21:38:03.443073: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 804 of 1000\n",
      "2024-09-10 21:38:13.042826: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 840 of 1000\n",
      "2024-09-10 21:38:22.903975: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 878 of 1000\n",
      "2024-09-10 21:38:33.188591: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 925 of 1000\n",
      "2024-09-10 21:38:43.418314: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:392] Filling up shuffle buffer (this may take a while): 965 of 1000\n",
      "2024-09-10 21:38:48.477094: I tensorflow/core/kernels/data/shuffle_dataset_op.cc:417] Shuffle buffer filled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  52/3189 [..............................] - ETA: 2:34:46 - loss: 0.7583 - accuracy: 0.4862"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras import mixed_precision  # Correct import for mixed precision\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Enable mixed precision training\n",
    "policy = mixed_precision.Policy('mixed_float16')\n",
    "mixed_precision.set_global_policy(policy)\n",
    "\n",
    "# Directories\n",
    "base_dir = '../real_vs_fake/real-vs-fake'\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')\n",
    "\n",
    "batch_size = 32  # Larger batch size\n",
    "img_size = (150, 150)\n",
    "\n",
    "# Function to preprocess the dataset\n",
    "def preprocess_image(image, label):\n",
    "    image = tf.image.resize(image, [150, 150])\n",
    "    image = image / 255.0  # rescale pixel values\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(directory):\n",
    "    dataset = tf.keras.preprocessing.image_dataset_from_directory(\n",
    "        directory,\n",
    "        image_size=img_size,\n",
    "        batch_size=batch_size,\n",
    "        label_mode='binary'\n",
    "    )\n",
    "    return dataset.map(preprocess_image)\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = load_dataset(train_dir).shuffle(1000).cache().prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = load_dataset(valid_dir).cache().prefetch(tf.data.AUTOTUNE)\n",
    "test_dataset = load_dataset(test_dir).cache().prefetch(tf.data.AUTOTUNE)\n",
    "\n",
    "# Load VGG16\n",
    "base_model = tf.keras.applications.VGG16(\n",
    "    weights='imagenet', \n",
    "    include_top=False, \n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "\n",
    "for layer in base_model.layers:  # Freeze most layers\n",
    "    layer.trainable = True\n",
    "\n",
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,\n",
    "    layers.GlobalAveragePooling2D(),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid', dtype='float32')  # Output for binary classification\n",
    "])\n",
    "\n",
    "# Compile model with a learning rate scheduler\n",
    "lr_schedule = tf.keras.optimizers.schedules.ExponentialDecay(\n",
    "    initial_learning_rate=0.001,\n",
    "    decay_steps=10000,\n",
    "    decay_rate=0.96,\n",
    "    staircase=True\n",
    ")\n",
    "\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=lr_schedule),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Adding early stopping\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',\n",
    "    mode='min',\n",
    "    patience=5,\n",
    "    restore_best_weights=True\n",
    ")\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_dataset,\n",
    "    epochs=100,  # High epoch count due to early stopping\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=[early_stopping]\n",
    ")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(test_dataset)\n",
    "print(f\"Test accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab7244a-b645-4b50-b405-8f873ed827a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_trainable_VGG16.h5')  # HDF5 format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e292e6-b990-483a-ba74-e4d6f1b351d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc35adb-ef85-419f-9c30-4344361f2137",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb744a26-9f9c-4d3d-bb6d-9e284f39cfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add model history to CSV so that we can make a cool graph out of it later\n",
    "# Pls change layer name :)\n",
    "history_df.to_csv(\"trainable_VGG16_model_history.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
