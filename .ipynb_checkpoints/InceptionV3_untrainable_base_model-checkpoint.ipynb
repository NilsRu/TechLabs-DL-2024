{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6c9f4764-dd71-4dea-863f-c51c0809859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9b3c4463-0a3e-4896-923a-6b9e293cb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attemtion to the path \n",
    "base_dir = '../real_vs_fake/real-vs-fake'\n",
    "#|--project\n",
    "#|-----TechLabs-DL-2024\n",
    "#|----------model.ipynb\n",
    "#|----------README.md\n",
    "#|-----real-vs-fake\n",
    "#|----------test\n",
    "#|----------train\n",
    "#|----------valid\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "20489172-5bd3-4a0b-addd-3e574891d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102041 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "img_size = (150,150)\n",
    "sample_count = 102041\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# train_generator.samples = 2 * sample_count  # causing errors in training\n",
    "#train_generator.batch_size = batch_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec11eb11-5f4a-4034-bc7f-d8afb889cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the InceptionV3\n",
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet', \n",
    "    include_top=False,  # We don't need the top layer (fully connected layer)\n",
    "    input_shape=(150, 150, 3)  # Input shape your images\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2696ebea-cae3-471a-822f-0c14e200f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761e073c-7955-4d1a-80cd-760e27fb16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,  # Add the base model as the first layer\n",
    "    layers.GlobalAveragePooling2D(),  # Reduces dimensions without further convolutions\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e1d2c3-528e-4594-8950-ed8a0a3d68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-04 23:22:41.795024: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-09-04 23:22:41.800459: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 798/5102 [===>..........................] - ETA: 29:47 - loss: 0.6681 - accuracy: 0.6323"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch= train_generator.samples // batch_size,  # number of batches per epoch\n",
    "    epochs=10,\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps= valid_generator.samples // batch_size\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8924657b-3de0-499a-9f57-1d91423542e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate on the Test Set\n",
    "print(\"Evaluating on Test Set:\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "Y_pred_test = model.predict(test_generator)\n",
    "y_pred_test = np.round(Y_pred_test).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(test_generator.classes, y_pred_test))\n",
    "\n",
    "print('Classification Report - Test Set')\n",
    "print(classification_report(test_generator.classes, y_pred_test, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // valid_generator.batch_size)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "Y_pred_val = model.predict(valid_generator)\n",
    "y_pred_val = np.round(Y_pred_val).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Validation Set')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred_val))\n",
    "\n",
    "print('Classification Report - Validation Set')\n",
    "print(classification_report(valid_generator.classes, y_pred_val, target_names=['Real', 'Fake']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "699f64a8-4a1b-4193-a642-9ce099ca5913",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "\n",
    "epochs_range = range(10)\n",
    "\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy')\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(epochs_range, loss, label='Training Loss')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
