{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9206f73-13db-4917-8a27-c3ca0abf119a",
   "metadata": {},
   "source": [
    "# Final Notebook of Group Pixel Patrol"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20c58008-e867-47e8-8992-89292e89b3c3",
   "metadata": {},
   "source": [
    "## Importing the libraries used in the notebook\n",
    "\n",
    "The following libraries are essential for importing the data, formatting it to fit into a tensorflow model and to run and evaluate the model:\n",
    "\n",
    "- os - For interacting with the operating system.\n",
    "- numpy (np) - For numerical operations and handling arrays.\n",
    "- tensorflow (tf) - For deep learning tasks.\n",
    "- tensorflow.keras.preprocessing.image (ImageDataGenerator) - For image preprocessing.\n",
    "- tensorflow.keras (layers, models) - For building neural networks.\n",
    "- sklearn.metrics (classification_report, confusion_matrix) - For evaluating classification models.\n",
    "- matplotlib.pyplot (plt) - For plotting graphs.\n",
    "- ipywidgets (widgets) - For creating interactive widgets in Jupyter Notebooks.\n",
    "- Python.display (display) - For displaying content in Jupyter Notebooks.\n",
    "- tensorflow.keras.preprocessing.image (image) - For loading and preprocessing images.\n",
    "- PIL (Image) - For image processing.\n",
    "- io - For handling input/output operations.\n",
    "- datetime (datetime) - For working with date and time.\n",
    "- tensorflow.keras.callbacks (EarlyStopping) - For controlling the training process.\n",
    "- pandas (pd) - For data manipulation and analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6c9f4764-dd71-4dea-863f-c51c0809859c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers, models\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import matplotlib.pyplot as plt\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from PIL import Image\n",
    "import io\n",
    "from datetime import datetime\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28bd6972-f02f-40b6-9149-d39e4cf0e5a4",
   "metadata": {},
   "source": [
    "## Defining the paths to the dataset\n",
    "\n",
    "The next code chung sets up paths to different data directories (train, valid, test) using os.path.join(), ensuring the correct formation of file paths. The base_dir points to a folder that contains subdirectories for training, validation, and testing data, which are necessary for the subsequent model training and evaluation.\n",
    "\n",
    "Additionally, the Path class from the pathlib library provides a cleaner, platform-independent way to handle file paths. It simplifies path manipulation using the / operator, makes file and directory operations easier, and improves code readability by offering intuitive methods like checking if a path exists, getting parent directories, and more."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9b3c4463-0a3e-4896-923a-6b9e293cb164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pay attemtion to the path \n",
    "base_dir = '../real_vs_fake/real-vs-fake'\n",
    "#|--project\n",
    "#|-----TechLabs-DL-2024\n",
    "#|----------model.ipynb\n",
    "#|----------README.md\n",
    "#|-----real-vs-fake\n",
    "#|----------test\n",
    "#|----------train\n",
    "#|----------valid\n",
    "\n",
    "train_dir = os.path.join(base_dir, 'train')\n",
    "valid_dir = os.path.join(base_dir, 'valid')\n",
    "test_dir = os.path.join(base_dir, 'test')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "369cb27d-f3bf-4cd5-a55f-3d996b274ae2",
   "metadata": {},
   "source": [
    "## Setting Parameters, Preprocessing and data generators\n",
    "\n",
    "### Setting Parameters\n",
    "\n",
    "The code begins by defining two key parameters:\n",
    "\n",
    "- batch_size = 20 sets the number of images that will be processed at a time during training, validation, or testing.\n",
    "- img_size = (150,150) resizes each image to 150x150 pixels before being input into the model, ensuring uniformity across the dataset.\n",
    "\n",
    "### Data Preprocessing\n",
    "\n",
    "The ImageDataGenerator(rescale=1./255) function is used to normalize the pixel values of all images by scaling them between 0 and 1. This is done by dividing each pixel value by 255. Normalization helps the model train more effectively by standardizing the input data.\n",
    "\n",
    "### Training Data Generator\n",
    "\n",
    "The train_generator is responsible for loading images from the train_dir, resizing them to img_size, and processing batches of 20 images at a time. It performs binary classification by categorizing the images as either ‘real’ or ‘fake’. The images are shuffled to introduce randomness into the training process, which helps prevent the model from overfitting to the data. A seed (seed=42) is set to ensure reproducibility of the shuffling across runs.\n",
    "\n",
    "### Validation Data Generator\n",
    "\n",
    "The valid_generator works similarly to the training data generator but loads data from the valid_dir for validation. The same image size, batch size, and binary classification process are applied. Like the training data, the validation data is also shuffled to introduce randomness during the validation process.\n",
    "\n",
    "### Test Data Generator\n",
    "\n",
    "The test_generator loads test data from the test_dir and prepares it for evaluation after the model is trained. However, unlike the training and validation generators, the test data is not shuffled (shuffle=False). This ensures that the model evaluates the images in a consistent order, making it easier to assess its final performance.\n",
    "\n",
    "These data generators automate the loading, normalization, and batching of images, simplifying the process of working with large datasets in machine learning projects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "20489172-5bd3-4a0b-addd-3e574891d992",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 102041 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n",
      "Found 20000 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "batch_size = 20\n",
    "img_size = (150,150)\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1./255)\n",
    "valid_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "valid_generator = valid_datagen.flow_from_directory(\n",
    "    valid_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=True,\n",
    "    subset=None,\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=img_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary',\n",
    "    classes=['real', 'fake'],\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79918f76-272d-4a94-ab9b-eb1961212e6b",
   "metadata": {},
   "source": [
    "## Loading pre-trained model\n",
    "\n",
    "The code initializes the InceptionV3 model from TensorFlow’s Keras applications. Here’s what each part does:\n",
    "\n",
    "- weights='imagenet': This parameter loads the model with pre-trained weights from the ImageNet dataset. This allows the model to start with features learned from a large and diverse image dataset, which can be helpful for transferring knowledge to new tasks.\n",
    "- include_top=False: By setting this to False, the model excludes the top fully connected layers that are typically used for classification in the original InceptionV3 model. This is useful when you’re using the model as a feature extractor and want to add your own custom layers on top.\n",
    "- input_shape=(150, 150, 3): This specifies the shape of the input images. Each image is resized to 150x150 pixels and has 3 color channels (RGB)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec11eb11-5f4a-4034-bc7f-d8afb889cb50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load InceptionV3\n",
    "base_model = tf.keras.applications.InceptionV3(\n",
    "    weights='imagenet', \n",
    "    include_top=False,  # We don't need the top layer (fully connected layer)\n",
    "    input_shape=(img_size[0], img_size[0], 3)  # Input shape of our images\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7610d84-5e1a-4d73-a0cc-581502f75008",
   "metadata": {},
   "source": [
    "## Making the pre-trained model trainable\n",
    "\n",
    "The code chung below is used to set all layers of the base_model to be trainable. Here’s what this does:\n",
    "\n",
    "- for layer in base_model.layers: This loop iterates through each layer in the base_model, which in this case is the InceptionV3 model.\n",
    "- layer.trainable = True: This line sets each layer’s trainable attribute to True, meaning that during training, the weights of these layers will be updated based on the training data.\n",
    "\n",
    "By default, pre-trained models like InceptionV3 may have their layers set to non-trainable if you only want to use them for feature extraction. Setting layer.trainable = True ensures that the model’s weights are adjusted during training, allowing you to fine-tune the model for your specific task or dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2696ebea-cae3-471a-822f-0c14e200f2bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model.layers:\n",
    "    layer.trainable = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d655bc1a-78be-4db7-a80f-3b38af340b6a",
   "metadata": {},
   "source": [
    "## Adding Custom Layers and Compiling the Model\n",
    "\n",
    "In this section, custom layers are added on top of the pre-trained base model (InceptionV3), and the model is then compiled.\n",
    "\n",
    "1.\tCustom Layers:\n",
    "- base_model: This is the pre-trained InceptionV3 model that extracts features from images.\n",
    "- GlobalAveragePooling2D: This layer simplifies the data by averaging feature maps, making it easier for the next layers.\n",
    "- Dense(512, activation='relu'): Fully connected layers with 512 units and ReLU activation learn and refine features.\n",
    "- Dropout(0.5): This helps prevent overfitting by randomly dropping 50% of the neurons during training.\n",
    "- Dense(1, activation='sigmoid'): The final layer outputs a probability for binary classification (e.g., ‘real’ or ‘fake’).\n",
    "2. Compiling the Model:\n",
    "- Optimizer: Adam with a learning rate of 0.001 updates the model weights during training.\n",
    "- Loss Function: Binary cross-entropy measures how well the model’s predictions match the actual labels.\n",
    "- Metric: Accuracy shows how often the model’s predictions are correct.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "761e073c-7955-4d1a-80cd-760e27fb16db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:At this time, the v2.11+ optimizer `tf.keras.optimizers.Adam` runs slowly on M1/M2 Macs, please use the legacy Keras optimizer instead, located at `tf.keras.optimizers.legacy.Adam`.\n",
      "WARNING:absl:There is a known slowdown when using v2.11+ Keras optimizers on M1/M2 Macs. Falling back to the legacy Keras optimizer, i.e., `tf.keras.optimizers.legacy.Adam`.\n"
     ]
    }
   ],
   "source": [
    "# Add custom layers on top of the base model\n",
    "model = models.Sequential([\n",
    "    base_model,  # Add the base model as the first layer\n",
    "    layers.GlobalAveragePooling2D(),  # Reduces dimensions without further convolutions\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dropout(0.5),\n",
    "    layers.Dense(512, activation='relu'),\n",
    "    layers.Dense(1, activation='sigmoid')  # Output layer for binary classification\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15721c9f-5a4a-4c9a-9ac9-adfcd689b50d",
   "metadata": {},
   "source": [
    "## Adding callbacks\n",
    "\n",
    "Early stopping is used to prevent overfitting and ensure the best model is saved during training:\n",
    "\n",
    "- monitor='val_loss': Watches the validation loss to track the model’s performance on unseen data.\n",
    "- mode='min': Stops training when the validation loss no longer decreases, aiming to minimize it.\n",
    "- patience=3: If there’s no improvement in validation loss for 3 consecutive epochs, training will stop.\n",
    "- restore_best_weights=True: Ensures that the model’s weights are reverted to the best state observed during training.\n",
    "\n",
    "This setup helps to automatically stop training when the model starts to overfit and keeps the best version of the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "373139bf-f46d-4985-984a-7e5de7c4daa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding early stopping to not miss best model\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_loss',     # Continiously validation loss\n",
    "    mode='min',             # Stops when val_loss is minimized\n",
    "    patience=3,             # Waits 3 epochs id no improvement\n",
    "    restore_best_weights=True  # Restores best model weights when training stops\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fb8c941-fdc9-4321-9c8a-1372704330a3",
   "metadata": {},
   "source": [
    "## Training the model\n",
    "\n",
    "The code trains the model with the following setup:\n",
    "\n",
    "- train_generator: Provides batches of training images.\n",
    "- steps_per_epoch: Defines how many batches are processed in each epoch, calculated by dividing the total number of training samples by the batch size.\n",
    "- ****epochs=100**: Sets the maximum number of training epochs. Early stopping will ensure that training stops early if there’s no improvement.\n",
    "- validation_data=valid_generator: Uses the validation data to evaluate the model’s performance after each epoch.\n",
    "- validation_steps: Specifies the number of validation batches to process, similar to steps_per_epoch.\n",
    "- callbacks=[early_stopping]: Uses the EarlyStopping callback to halt training when there’s no improvement in validation loss, ensuring the best model is saved.\n",
    "\n",
    "This configuration allows the model to train efficiently while monitoring for overfitting and adjusting training duration automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e5e1d2c3-528e-4594-8950-ed8a0a3d68cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 20:41:40.759261: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n",
      "2024-09-05 20:41:40.762273: W tensorflow/tsl/platform/profile_utils/cpu_utils.cc:128] Failed to get CPU frequency: 0 Hz\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5102/5102 [==============================] - ETA: 0s - loss: 0.2774 - accuracy: 0.8832"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-05 21:39:11.782081: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5102/5102 [==============================] - 3624s 710ms/step - loss: 0.2774 - accuracy: 0.8832 - val_loss: 0.1656 - val_accuracy: 0.9347\n",
      "Epoch 2/100\n",
      "5102/5102 [==============================] - 3647s 715ms/step - loss: 0.1086 - accuracy: 0.9600 - val_loss: 0.0777 - val_accuracy: 0.9707\n",
      "Epoch 3/100\n",
      "5102/5102 [==============================] - 3516s 689ms/step - loss: 0.0743 - accuracy: 0.9715 - val_loss: 1.3747 - val_accuracy: 0.9636\n",
      "Epoch 4/100\n",
      "5102/5102 [==============================] - 3512s 688ms/step - loss: 0.0617 - accuracy: 0.9764 - val_loss: 0.0611 - val_accuracy: 0.9779\n",
      "Epoch 5/100\n",
      "5102/5102 [==============================] - 3502s 686ms/step - loss: 0.0541 - accuracy: 0.9788 - val_loss: 0.1460 - val_accuracy: 0.9657\n",
      "Epoch 6/100\n",
      "5102/5102 [==============================] - 3502s 686ms/step - loss: 0.0440 - accuracy: 0.9827 - val_loss: 0.0771 - val_accuracy: 0.9849\n",
      "Epoch 7/100\n",
      "5102/5102 [==============================] - 3504s 687ms/step - loss: 0.0373 - accuracy: 0.9845 - val_loss: 0.0824 - val_accuracy: 0.9688\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples // batch_size,  # number of batches per epoch\n",
    "    epochs=100,  # high number of epochs is ok due to early stopping\n",
    "    validation_data=valid_generator,\n",
    "    validation_steps=valid_generator.samples // batch_size,\n",
    "    callbacks=[early_stopping]   # EarlyStopping callback \n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fc3b526-f43b-43e9-a27c-4d1895e274a1",
   "metadata": {},
   "source": [
    "## Evaluating the model\n",
    "\n",
    "The code performs evaluation on both the test and validation sets with the following steps:\n",
    "\n",
    "- Evaluate on the Test Set:\n",
    "- model.evaluate(test_generator): Computes the loss and accuracy on the test data.\n",
    "- print(f\"Test Accuracy: {test_acc:.2f}\"): Displays the accuracy of the model on the test set.\n",
    "- model.predict(test_generator): Predicts the labels for the test images.\n",
    "- np.round(Y_pred_test).astype(int): Rounds the predictions to the nearest integer (0 or 1).\n",
    "- confusion_matrix(test_generator.classes, y_pred_test): Displays the confusion matrix, showing true vs. predicted classifications.\n",
    "- classification_report(test_generator.classes, y_pred_test, target_names=['Real', 'Fake']): Prints a detailed classification report with precision, recall, and F1-score for each class.\n",
    "- Evaluate on the Validation Set:\n",
    "- model.evaluate(valid_generator): Computes the loss and accuracy on the validation data.\n",
    "- print(f\"Validation Accuracy: {val_acc:.2f}\"): Displays the accuracy of the model on the validation set.\n",
    "- model.predict(valid_generator): Predicts the labels for the validation images.\n",
    "- np.round(Y_pred_val).astype(int): Rounds the predictions to the nearest integer.\n",
    "- confusion_matrix(valid_generator.classes, y_pred_val): Displays the confusion matrix for the validation set.\n",
    "- classification_report(valid_generator.classes, y_pred_val, target_names=['Real', 'Fake']): Prints the classification report for the validation set.\n",
    "\n",
    "This evaluation helps assess the model’s performance on unseen test and validation data, providing insights into accuracy and detailed metrics.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8924657b-3de0-499a-9f57-1d91423542e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating on Test Set:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 03:35:07.857827: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0647 - accuracy: 0.9773\n",
      "Test Accuracy: 0.98\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 03:38:02.128147: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 174s 174ms/step\n",
      "Confusion Matrix - Test Set\n",
      "[[9793  207]\n",
      " [ 246 9754]]\n",
      "Classification Report - Test Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.98      0.98      0.98     10000\n",
      "        Fake       0.98      0.98      0.98     10000\n",
      "\n",
      "    accuracy                           0.98     20000\n",
      "   macro avg       0.98      0.98      0.98     20000\n",
      "weighted avg       0.98      0.98      0.98     20000\n",
      "\n",
      "\n",
      "Evaluating on Validation Set:\n",
      "   1/1000 [..............................] - ETA: 3:00 - loss: 0.0143 - accuracy: 1.0000"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 03:40:56.590096: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 174s 174ms/step - loss: 0.0611 - accuracy: 0.9779\n",
      "Validation Accuracy: 0.98\n",
      "   1/1000 [..............................] - ETA: 3:19"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-06 03:43:50.391365: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'Placeholder/_0' with dtype int32\n",
      "\t [[{{node Placeholder/_0}}]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000/1000 [==============================] - 174s 174ms/step\n",
      "Confusion Matrix - Validation Set\n",
      "[[4987 5013]\n",
      " [5035 4965]]\n",
      "Classification Report - Validation Set\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.50      0.50      0.50     10000\n",
      "        Fake       0.50      0.50      0.50     10000\n",
      "\n",
      "    accuracy                           0.50     20000\n",
      "   macro avg       0.50      0.50      0.50     20000\n",
      "weighted avg       0.50      0.50      0.50     20000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate on the Test Set\n",
    "print(\"Evaluating on Test Set:\")\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples // test_generator.batch_size)\n",
    "print(f\"Test Accuracy: {test_acc:.2f}\")\n",
    "\n",
    "Y_pred_test = model.predict(test_generator)\n",
    "y_pred_test = np.round(Y_pred_test).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Test Set')\n",
    "print(confusion_matrix(test_generator.classes, y_pred_test))\n",
    "\n",
    "print('Classification Report - Test Set')\n",
    "print(classification_report(test_generator.classes, y_pred_test, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Evaluate on the Validation Set\n",
    "print(\"\\nEvaluating on Validation Set:\")\n",
    "val_loss, val_acc = model.evaluate(valid_generator, steps=valid_generator.samples // valid_generator.batch_size)\n",
    "print(f\"Validation Accuracy: {val_acc:.2f}\")\n",
    "\n",
    "Y_pred_val = model.predict(valid_generator)\n",
    "y_pred_val = np.round(Y_pred_val).astype(int)\n",
    "\n",
    "print('Confusion Matrix - Validation Set')\n",
    "print(confusion_matrix(valid_generator.classes, y_pred_val))\n",
    "\n",
    "print('Classification Report - Validation Set')\n",
    "print(classification_report(valid_generator.classes, y_pred_val, target_names=['Real', 'Fake']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "444d48b6-1eeb-410f-a0ef-66c5aed55728",
   "metadata": {},
   "source": [
    "## Saving the model\n",
    "\n",
    "The following code saves the model on drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bebeb84a-1a50-44fb-8791-8601c86c6439",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('pretrained_trainable_version2.h5')  # HDF5 format"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c6a2a18-d023-47ed-b3c4-82fb85490835",
   "metadata": {},
   "source": [
    "## Plotting performance\n",
    "\n",
    "The following code plots the models performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a57587e-06fb-41eb-91fe-cbf29a53347e",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc = history.history['accuracy']\n",
    "val_acc = history.history['val_accuracy']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs_range = history.epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a24b788d-c5be-4ba0-953e-8e00c442157b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_range, acc, label='Training Accuracy', color='blue', linestyle='--')\n",
    "plt.plot(epochs_range, val_acc, label='Validation Accuracy', color='green', linestyle='-')\n",
    "plt.legend(loc='lower right')\n",
    "plt.title('Training and Validation Accuracy', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Accuracy', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=epochs_range)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6d42151-b92b-4a6a-b29a-6f4003d3eaa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(epochs_range, loss, label='Training Loss', color='blue', linestyle='--')\n",
    "plt.plot(epochs_range, val_loss, label='Validation Loss', color='green', linestyle='-')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title('Training and Validation Loss', fontsize=14)\n",
    "plt.xlabel('Epochs', fontsize=12)\n",
    "plt.ylabel('Loss', fontsize=12)\n",
    "plt.grid(True)\n",
    "plt.xticks(ticks=epochs_range)  \n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c09409a-5ca2-4d16-beeb-3fa7345adafc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cm = confusion_matrix(test_generator.classes, y_pred_test)\n",
    "# Plot confusion \n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, interpolation='nearest', cmap=plt.cm.Blues)\n",
    "plt.title('Confusion Matrix')\n",
    "plt.colorbar()\n",
    "tick_marks = np.arange(2)\n",
    "plt.xticks(tick_marks, ['Real', 'Fake'], rotation=45)\n",
    "plt.yticks(tick_marks, ['Real', 'Fake']\n",
    "           \n",
    "thresh = cm.max() / 2.\n",
    "for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "    plt.text(j, i, format(cm[i, j], 'd'),\n",
    "             horizontalalignment='center',\n",
    "             color='white' if cm[i, j] > thresh else 'black')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.ylabel('True label')\n",
    "plt.xlabel('Predicted label')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0744456e-9c93-4858-81c8-39f9f995c905",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_classes = np.argmax(y_pred_test, axis=1)\n",
    "y_true = test_generator.classes\n",
    "misclassified_idx = np.where(y_pred_classes != y_true)[0]\n",
    "\n",
    "label_map = {0: 'Real', 1: 'Fake'}\n",
    "\n",
    "plt.figure(figsize=(12,12))\n",
    "plt.suptitle('Misclassified Images', fontsize=16)  # Adding the main title\n",
    "\n",
    "for i, idx in enumerate(misclassified_idx[11:20]):  # Showing first 9 misclassified images\n",
    "    plt.subplot(3,3,i+1)\n",
    "    img = test_generator.filepaths[idx]\n",
    "    img = image.load_img(img, target_size=(150, 150))\n",
    "    plt.imshow(img)\n",
    "    true_label = label_map[y_true[idx]]\n",
    "    predicted_label = label_map[y_pred_classes[idx]]\n",
    "    plt.title(f\"True: {true_label}, Pred: {predicted_label}\")\n",
    "    plt.axis('off')\n",
    "\n",
    "plt.tight_layout(rect=[0, 0, 1, 0.95])  # Adjust layout to fit the title\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "278df0f8-3fae-4feb-bfa8-4433d53985f9",
   "metadata": {},
   "source": [
    "## Export history\n",
    "\n",
    "The following code exports model history and performance ans pandas dataframe and saves it to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "47cb7624-c679-4861-b13c-581b23e9bfcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "history_df = pd.DataFrame(history.history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7ef61bac-7d84-462e-924c-c2c6f10663f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_accuracy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.277406</td>\n",
       "      <td>0.883181</td>\n",
       "      <td>0.165561</td>\n",
       "      <td>0.93465</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.108603</td>\n",
       "      <td>0.960047</td>\n",
       "      <td>0.077681</td>\n",
       "      <td>0.97065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.074325</td>\n",
       "      <td>0.971476</td>\n",
       "      <td>1.374691</td>\n",
       "      <td>0.96365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.061739</td>\n",
       "      <td>0.976407</td>\n",
       "      <td>0.061111</td>\n",
       "      <td>0.97790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.054089</td>\n",
       "      <td>0.978838</td>\n",
       "      <td>0.146000</td>\n",
       "      <td>0.96570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.044013</td>\n",
       "      <td>0.982700</td>\n",
       "      <td>0.077076</td>\n",
       "      <td>0.98490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.037317</td>\n",
       "      <td>0.984542</td>\n",
       "      <td>0.082415</td>\n",
       "      <td>0.96875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  accuracy  val_loss  val_accuracy\n",
       "0  0.277406  0.883181  0.165561       0.93465\n",
       "1  0.108603  0.960047  0.077681       0.97065\n",
       "2  0.074325  0.971476  1.374691       0.96365\n",
       "3  0.061739  0.976407  0.061111       0.97790\n",
       "4  0.054089  0.978838  0.146000       0.96570\n",
       "5  0.044013  0.982700  0.077076       0.98490\n",
       "6  0.037317  0.984542  0.082415       0.96875"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c69e75a5-31de-4259-8b0d-bda5e2b812ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# lets add model history to CSV so that we can make a cool graph out of it later\n",
    "# Pls change layer name :)\n",
    "history_df.to_csv(\"trainable_google_layer_model_history.csv\", index = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
